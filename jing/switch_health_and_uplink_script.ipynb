{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Switch Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     result:    \n",
    "#         String orgID;\n",
    "#         String siteID;\n",
    "#         String deviceID; // device = \"switch\"\n",
    "#         String deviceModel;\n",
    "#         String deviceVersion;\n",
    "#         Long timeStamp;\n",
    "#         Integer duration = 60;\n",
    "\n",
    "#         String clientID =\"\"; // \"interface_name for throughput; Chassis_index\n",
    "#         String metric = \"\";  // switch-throughput, switch-health,  switch-\n",
    "#         String classifier = \"\";\n",
    "#         Float value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Flattening\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType, FloatType, MapType, LongType\n",
    "from pyspark.sql.functions import lit, udf, size, avg, min as min_, max as max_, sum as sum_, count, countDistinct, arrays_zip, col, mean, stddev, struct, explode, explode_outer, unix_timestamp, sum as sum_\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import collect_list, collect_set, row_number, dense_rank, lead, lag, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import collections\n",
    "from collections import deque\n",
    "import redis\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-11-07'\n",
    "df = spark.read.parquet('s3://mist-secorapp-staging/oc-stats-analytics/oc-stats-analytics-staging/dt='+date+'/*')\n",
    "\n",
    "dfeng = df.select('id',\n",
    "                 'mac',\n",
    "                 'org_id',\n",
    "                 'site_id',\n",
    "                 'when',\n",
    "                 'remote_addr',\n",
    "                 'hostname',\n",
    "                 'model',\n",
    "                 'firmware_version',\n",
    "                 'serial_number',\n",
    "                 'stpbridge_protocol',\n",
    "                 'stpbridge_root_id',\n",
    "                 'stpbridge_root_cost',\n",
    "                 'stpbridge_root_port',\n",
    "                 'stpbridge_hello_time',\n",
    "                 'stpbridge_max_age',\n",
    "                 'stpbridge_forward_delay',\n",
    "                 'stpbridge_msg_age',\n",
    "                 'stpbridge_topo_chg_cnt',\n",
    "                 'stpbridge_last_topo_chg',\n",
    "                 'stpbridge_bridge_id',\n",
    "                 'uptime',\n",
    "                 'stats_delta',\n",
    "                 'delta',\n",
    "                 'deltaErrorMsg',\n",
    "                 'delta_interval',\n",
    "                 'poe_controller_module_index',\n",
    "                 'poe_controller_max_power',\n",
    "                 'poe_controller_consumption',\n",
    "                 'poe_controller_guardband',\n",
    "                 explode_outer('chassis_routing_engines').alias('eng'))\n",
    "\n",
    "dfeng = dfeng.select('id',\n",
    "                 'mac',\n",
    "                 'org_id',\n",
    "                 'site_id',\n",
    "                 'when',\n",
    "                 'remote_addr',\n",
    "                 'hostname',\n",
    "                 'model',\n",
    "                 'firmware_version',\n",
    "                 'serial_number',\n",
    "                 'stpbridge_protocol',\n",
    "                 'stpbridge_root_id',\n",
    "                 'stpbridge_root_cost',\n",
    "                 'stpbridge_root_port',\n",
    "                 'stpbridge_hello_time',\n",
    "                 'stpbridge_max_age',\n",
    "                 'stpbridge_forward_delay',\n",
    "                 'stpbridge_msg_age',\n",
    "                 'stpbridge_topo_chg_cnt',\n",
    "                 'stpbridge_last_topo_chg',\n",
    "                 'stpbridge_bridge_id',\n",
    "                 'uptime',\n",
    "                 'stats_delta',\n",
    "                 'delta',\n",
    "                 'deltaErrorMsg',\n",
    "                 'delta_interval',\n",
    "                 'poe_controller_module_index',\n",
    "                 'poe_controller_max_power',\n",
    "                 'poe_controller_consumption',\n",
    "                 'poe_controller_guardband',\n",
    "                  col('eng.module_index').alias('module_index'),\n",
    "                     col('eng.is_master').alias('is_master'),\n",
    "                     col('eng.status').alias('status'),\n",
    "                     col('eng.temp_celsius').alias('temp_celsius'),\n",
    "                     col('eng.memory_total_mb').alias('memory_total_mb'),\n",
    "                     col('eng.memory_in_use_mb').alias('memory_in_use_mb'),\n",
    "                     col('eng.cpu_user').alias('cpu_user'),\n",
    "                     col('eng.cpu_background').alias('cpu_background'),\n",
    "                     col('eng.cpu_system').alias('cpu_system'),\n",
    "                     col('eng.cpu_interrupt').alias('cpu_interrupt'),\n",
    "                     col('eng.cpu_idle').alias('cpu_idle'),\n",
    "                     col('eng.cputemp_celsius').alias('cputemp_celsius'),\n",
    "                     col('eng.model').alias('eng_model'),\n",
    "                     col('eng.last_reboot_reason').alias('last_reboot_reason'),\n",
    "                     col('eng.load_avg').alias('load_avg'))\n",
    "                     \n",
    "dfeng = dfeng.withColumn('load_avg1', dfeng.load_avg[0])  \n",
    "# memorypct = udf(lambda x: x[0]/x[1], FloatType())\n",
    "# dfeng = dfeng.withColumn('memory_pct', memorypct(struct('memory_in_use_mb','memory_total_mb')))\n",
    "dfeng = dfeng.filter(col('delta')==True)\n",
    "dfeng.write.parquet('s3://mist-data-science-dev/jing/switch/engines'+date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built baseline and upperlimit using historical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memorypct(dfeng):\n",
    "    # calculate memory %\n",
    "    memorypct = udf(lambda x: (x[0]/x[1])*100, FloatType())\n",
    "    dfeng = dfeng.withColumn('memory_pct', memorypct(struct('memory_in_use_mb','memory_total_mb')))\n",
    "\n",
    "    # filter delts=T\n",
    "    dfeng = dfeng.filter(col('delta')==True)\n",
    "    return dfeng\n",
    "\n",
    "def get_baseline(df0):\n",
    "    # Build Baseline\n",
    "    df1 = df0.groupby('mac', 'module_index').agg(avg('temp_celsius').alias('avg_temp'), stddev('temp_celsius').alias('std_temp') \\\n",
    "                                                ,avg('memory_pct').alias('avg_memorypct'), stddev('memory_pct').alias('std_memorypct') \\\n",
    "                                                ,avg('memory_in_use_mb').alias('avg_memory'), stddev('memory_in_use_mb').alias('std_memory'))\n",
    "    df2 = df0.groupby('model').agg(avg('memory_pct').alias('avg_memorypct_model'), stddev('memory_pct').alias('std_memorypct_model'), \\\n",
    "                                                       avg('memory_in_use_mb').alias('avg_memory_model'), stddev('memory_in_use_mb').alias('std_memory_model'))\n",
    "    df1 = df1.withColumnRenamed('mac','mac1') \\\n",
    "            .withColumnRenamed('module_index','module_index1')\n",
    "    df2 = df2.withColumnRenamed('model','model2')\n",
    "    \n",
    "    df0 = df0.join(df1, (df0.mac==df1.mac1)&(df0.module_index==df1.module_index1), 'inner') \\\n",
    "                .join(df2, (df0.model==df2.model2), 'inner')\n",
    "    \n",
    "    return df0\n",
    "\n",
    "def get_upper_limit(df0):\n",
    "    upper = udf(lambda x: x[0]+3*x[1], FloatType())\n",
    "    df0 = df0.withColumn('upper_temp', upper(struct('avg_temp', 'std_temp'))) \\\n",
    "                .withColumn('upper_memorypct', upper(struct('avg_memorypct', 'std_memorypct'))) \\\n",
    "                .withColumn('upper_memory', upper(struct('avg_memory', 'std_memory'))) \\\n",
    "                .withColumn('upper_memorypct_model', upper(struct('avg_memorypct_model', 'std_memorypct_model'))) \\\n",
    "                .withColumn('upper_memory_model', upper(struct('avg_memory_model', 'std_memory_model'))) \n",
    "                \n",
    "\n",
    "    df0 = df0.select('mac','module_index','org_id','site_id','model','firmware_version','upper_temp','upper_memory','upper_memorypct','upper_memory_model','upper_memorypct_model')\n",
    "    return df0\n",
    "\n",
    "def main(dfeng):\n",
    "    dfeng = get_memorypct(dfeng)\n",
    "    df0 = get_baseline(dfeng)\n",
    "    df0 = get_upper_limit(df0).distinct()\n",
    "    df0.write.parquet('s3://mist-data-science-dev/jing/switch_health/baseline_wmodel')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # input dfeng is flattened engine data\n",
    "    dfeng = dfeng.select('mac','module_index','when','model','temp_celsius','memory_in_use_mb','memory_total_mb','cpu_idle', 'org_id','site_id','model','firmware_version')    \n",
    "\n",
    "    main(dfeng)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-80-d380d8604b2b>, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-80-d380d8604b2b>\"\u001b[0;36m, line \u001b[0;32m68\u001b[0m\n\u001b[0;31m    df = df.withColumn('detection', detection(''))\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    " \n",
    "def get_memorypct(dfeng):\n",
    "    # calculate memory %\n",
    "    memorypct = udf(lambda x: (x[0]/x[1])*100, FloatType())\n",
    "    dfeng = dfeng.withColumn('memory_pct', memorypct(struct('memory_in_use_mb','memory_total_mb')))\n",
    "\n",
    "    # filter delts=T\n",
    "    dfeng = dfeng.filter(col('delta')==True)\n",
    "    return dfeng\n",
    "\n",
    "def smooth(list, degree=5):\n",
    "    window = degree*2-1\n",
    "    weight = numpy.array([1.0]*window)\n",
    "    weightGauss = []\n",
    "    for i in range(window):\n",
    "        i = i-degree+1\n",
    "        frac = i/float(window)\n",
    "        gauss = 1/(numpy.exp((4*(frac))**2))\n",
    "        weightGauss.append(gauss)\n",
    "    weight = numpy.array(weightGauss)*weight\n",
    "    smoothed = [0.0]*(len(list)-window)\n",
    "    for i in range(len(smoothed)):\n",
    "        smoothed[i] = (sum(numpy.array(list[i:i+window])*weight)/sum(weight)).item()\n",
    "    return smoothed \n",
    "\n",
    "def smoothwhen(list, degree=5):\n",
    "    window = degree*2-1\n",
    "    return list[:(len(list)-window)]\n",
    "\n",
    "def get_smooth(df):\n",
    "    df = df.groupby('mac','module_index').agg(collect_list('memory_pct').alias('lst_memorypct'), \\\n",
    "                                              collect_list('memory_in_use_mb').alias('lst_memory'), \\\n",
    "                                             collect_list('cpu_idle').alias('lst_cpu'), \\\n",
    "                                             collect_list('temp_celsius').alias('lst_temp'),\n",
    "                                             collect_list('when').alias('lst_when'))\n",
    "    smooth_udf = udf(smooth, ArrayType(FloatType()))\n",
    "    smoothwhen_udf = udf(smoothwhen, ArrayType(LongType()))\n",
    "    df = df.withColumn('s_temp', smooth_udf('lst_temp')) \\\n",
    "            .withColumn('s_cpu', smooth_udf('lst_cpu')) \\\n",
    "            .withColumn('s_memory', smooth_udf('lst_memory')) \\\n",
    "            .withColumn('s_memorypct', smooth_udf('lst_memorypct')) \\\n",
    "            .withColumn('s_when', smoothwhen_udf('lst_when'))\n",
    "    df = df.drop('lst_memory','lst_temp','lst_cpu', 'lst_when', 'lst_memorypct')     \n",
    "    df = df.withColumn('smooth_cols', arrays_zip('s_temp','s_cpu','s_memory', 's_memorypct', 's_when')) \\\n",
    "            .withColumn('smooth', explode('smooth_cols')) \\\n",
    "            .select('mac','module_index', \\\n",
    "                    col('smooth.s_temp').alias('stemp'), \\\n",
    "                    col('smooth.s_cpu').alias('scpu'), \\\n",
    "                    col('smooth.s_memory').alias('smemory'), \\\n",
    "                    col('smooth.s_memorypct').alias('smemorypct'), \\\n",
    "                    col('smooth.s_when').alias('swhen'))\n",
    "    return df\n",
    "\n",
    "def get_classifier(df):\n",
    "    \n",
    "    def AD_func(x):\n",
    "        if x[0] > x[1]: return 1\n",
    "        else: return 0\n",
    "    def alarm_temp(x):\n",
    "        if x > 70: return 1\n",
    "        else: return 0\n",
    "#     def alarm_memory(x):\n",
    "#         if x > 90: return 1\n",
    "#         else: return 0\n",
    "    def alarm_cpu(x):\n",
    "        if x < 10: return 1  # 4% of all records\n",
    "        else: return 0  \n",
    "\n",
    "    AD_func = udf(AD_func, IntegerType())    \n",
    "    alarm_temp = udf(alarm_temp, IntegerType())\n",
    "#     alarm_memory = udf(alarm_memory, IntegerType())\n",
    "    alarm_cpu = udf(alarm_cpu, IntegerType())\n",
    "\n",
    "    df = df.withColumn('AD_temp', AD_func(struct('stemp', 'upper_temp')))\n",
    "    df = df.withColumn('AD_memory', AD_func(struct('smemory', 'upper_memory')))\n",
    "    df = df.withColumn('AD_memorypct', AD_func(struct('smemorypct', 'upper_memorypct')))\n",
    "    df = df.withColumn('AD_memory_model', AD_func(struct('smemory', 'upper_memory_model')))\n",
    "    df = df.withColumn('AD_memorypct_model', AD_func(struct('smemorypct', 'upper_memorypct_model')))\n",
    "    df = df.withColumn('alarm_temp', alarm_temp('stemp'))\n",
    "#     df = df.withColumn('alarm_memory', alarm_memory('smemory'))\n",
    "    df = df.withColumn('alarm_cpu', alarm_cpu('scpu'))\n",
    "    \n",
    "    \n",
    "    def detection(x):\n",
    "        root = np.sum([i for i in x]).item()        \n",
    "        if (x[2] == 1) & (x[0] == 1): \n",
    "            root -= 1\n",
    "        if (x[3] == 1) & (x[1] == 1):\n",
    "            root -= 1\n",
    "        return root\n",
    "    detection = udf(detection, IntegerType())\n",
    "    df = df.withColumn('detection', detection(struct('AD_temp','AD_memory','alarm_temp','AD_memory','AD_memorypct','AD_memory_model','AD_memorypct_model','alarm_cpu'))) \n",
    "    return df\n",
    "\n",
    "def get_histogram(df):\n",
    "    splits = [-float('inf'),0,20,40,60,80,100,float('inf')]\n",
    "    tempbucket = Bucketizer(splits=splits, inputCol=\"stemp\", outputCol=\"tempbucket\") \n",
    "    tempbucket = tempbucket.transform(df) \n",
    "    temphist = tempbucket.groupby('mac','module_index','tempbucket').count()\n",
    "    memorybucket = Bucketizer(splits=splits, inputCol=\"smemory\", outputCol=\"memorybucket\") \n",
    "    memorybucket = memorybucket.transform(df) \n",
    "    memoryhist = memorybucket.groupby('mac','module_index','memorybucket').count()\n",
    "    cpubucket = Bucketizer(splits=splits, inputCol=\"scpu\", outputCol=\"cpubucket\") \n",
    "    cpubucket = cpubucket.transform(df) \n",
    "    cpuhist = cpubucket.groupby('mac','module_index','cpubucket').count()\n",
    "    return temphist, memoryhist, cpuhist\n",
    "    \n",
    "def __main__(dfeng):\n",
    "    dfin = dfeng.select('mac','module_index','when','temp_celsius','memory_in_use_mb','memory_total_mb','cpu_idle', 'org_id','site_id','model','firmware_version')\n",
    "    df = get_memorypct(dfin)\n",
    "    df = get_smooth(df)\n",
    "    \n",
    "    # add baseline to df\n",
    "    df0 = spark.read.parquet('s3://mist-data-science-dev/jing/switch_health/baseline')    \n",
    "    df = df.join(df0, (df.mac == df0.mac1)&(df.module_index == df0.module_index1), 'left') \\\n",
    "            .drop('mac1','module_index1')\n",
    "    \n",
    "    classifier = get_classifier(df) \n",
    "    classifier.toPandas().to_csv('classifier.csv')\n",
    "    classifier.write.parquet('s3://mist-data-science-dev/jing/switch_health/classifier')\n",
    "    \n",
    "    temphist, memoryhist, cpuhist = get_histogram(df)\n",
    "    temphist.write.parquet('s3://mist-data-science-dev/jing/switch_health/temphist')\n",
    "    memoryhist.write.parquet('s3://mist-data-science-dev/jing/switch_health/memoryhist')\n",
    "    cpuhist.write.parquet('s3://mist-data-science-dev/jing/switch_health/cpuhist')\n",
    "    temphist.sort('tempbucket').toPandas().to_csv('temphist.csv')\n",
    "    memoryhist.sort('memorybucket').toPandas().to_csv('memoryhist.csv')\n",
    "    cpuhist.sort('cpubucket').toPandas().to_csv('cpuhist.csv')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    __main__(dfeng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------END-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. UPLINK #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Flattening\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType, FloatType, MapType, LongType\n",
    "from pyspark.sql.functions import lit, udf, size, avg, min as min_, max as max_, sum as sum_, count, countDistinct, arrays_zip, col, mean, stddev, struct, explode, explode_outer, unix_timestamp, sum as sum_\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import collect_list, collect_set, row_number, dense_rank, lead, lag, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import collections\n",
    "from collections import deque\n",
    "import redis\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten interface\n",
    "date = '2019-11-08'\n",
    "df = spark.read.parquet('s3://mist-secorapp-staging/oc-stats-analytics/oc-stats-analytics-staging/dt='+date+'/*')\n",
    "\n",
    "dfin = df.select('id',\n",
    "                 'mac',\n",
    "                 'org_id',\n",
    "                 'site_id',\n",
    "                 'when',\n",
    "                 'remote_addr',\n",
    "                 'hostname',\n",
    "                 'model',\n",
    "                 'firmware_version',\n",
    "                 'serial_number',\n",
    "                 'stpbridge_protocol',\n",
    "                 'stpbridge_root_id',\n",
    "                 'stpbridge_root_cost',\n",
    "                 'stpbridge_root_port',\n",
    "                 'stpbridge_hello_time',\n",
    "                 'stpbridge_max_age',\n",
    "                 'stpbridge_forward_delay',\n",
    "                 'stpbridge_msg_age',\n",
    "                 'stpbridge_topo_chg_cnt',\n",
    "                 'stpbridge_last_topo_chg',\n",
    "                 'stpbridge_bridge_id',\n",
    "                 'uptime',\n",
    "                 'stats_delta',\n",
    "                 'delta',\n",
    "                 'deltaErrorMsg',\n",
    "                 'delta_interval',\n",
    "                 'poe_controller_module_index',\n",
    "                 'poe_controller_max_power',\n",
    "                 'poe_controller_consumption',\n",
    "                 'poe_controller_guardband',\n",
    "                 explode_outer('interfaces').alias('interfaces'))\n",
    "\n",
    "dfin = dfin.select('id',\n",
    "                 'mac',\n",
    "                 'org_id',\n",
    "                 'site_id',\n",
    "                 'when',\n",
    "                 'remote_addr',\n",
    "                 'hostname',\n",
    "                 'model',\n",
    "                 'firmware_version',\n",
    "                 'serial_number',\n",
    "                 'stpbridge_protocol',\n",
    "                 'stpbridge_root_id',\n",
    "                 'stpbridge_root_cost',\n",
    "                 'stpbridge_root_port',\n",
    "                 'stpbridge_hello_time',\n",
    "                 'stpbridge_max_age',\n",
    "                 'stpbridge_forward_delay',\n",
    "                 'stpbridge_msg_age',\n",
    "                 'stpbridge_topo_chg_cnt',\n",
    "                 'stpbridge_last_topo_chg',\n",
    "                 'stpbridge_bridge_id',\n",
    "                 'uptime',\n",
    "                 'stats_delta',\n",
    "                 'delta',\n",
    "                 'deltaErrorMsg',\n",
    "                 'delta_interval',\n",
    "                 'poe_controller_module_index',\n",
    "                 'poe_controller_max_power',\n",
    "                 'poe_controller_consumption',\n",
    "                 'poe_controller_guardband',\n",
    "                  col('interfaces.name').alias('name'),\n",
    "                   col('interfaces.link').alias('link'),\n",
    "                   col('interfaces.full_duplex').alias('full_duplex'),\n",
    "                   col('interfaces.mbps').alias('mbps'),\n",
    "                   col('interfaces.mtu').alias('mtu'),\n",
    "                   col('interfaces.address').alias('address'),\n",
    "                   col('interfaces.admin_status').alias('admin_status'),\n",
    "                   col('interfaces.last_flapped').alias('last_flapped'),\n",
    "                   col('interfaces.errors').alias('errors'),\n",
    "                   col('interfaces.poe_enabled').alias('poe_enabled'),\n",
    "                   col('interfaces.poe_status').alias('poe_status'),\n",
    "                   col('interfaces.poe_power_limit').alias('poe_power_limit'),\n",
    "                   col('interfaces.poe_power').alias('poe_power'),\n",
    "                   col('interfaces.poe_priority').alias('poe_priority'),\n",
    "                   col('interfaces.poe_class').alias('poe_class'),\n",
    "                   col('interfaces.poe_mode').alias('poe_mode'),\n",
    "                   col('interfaces.rx_bytes').alias('rx_bytes'),\n",
    "                   col('interfaces.tx_bytes').alias('tx_bytes'),\n",
    "                   col('interfaces.rx_packets').alias('rx_packets'),\n",
    "                   col('interfaces.tx_packets').alias('tx_packets'),\n",
    "                   col('interfaces.rx_bps').alias('rx_bps'),\n",
    "                   col('interfaces.tx_bps').alias('tx_bps'),\n",
    "                   col('interfaces.rx_errors').alias('rx_errors'),\n",
    "                   col('interfaces.rx_undersize_errors').alias('rx_undersize_errors'),\n",
    "                   col('interfaces.rx_oversize_errors').alias('rx_oversize_errors'),\n",
    "                   col('interfaces.rx_fcserrors').alias('rx_fcserrors'),\n",
    "                   col('interfaces.rx_overrun_errors').alias('rx_overrun_errors'),\n",
    "                   col('interfaces.rx_discards').alias('rx_discards'),\n",
    "                   col('interfaces.tx_errors').alias('tx_errors'),\n",
    "                   col('interfaces.tx_drops').alias('tx_drops'),\n",
    "                   col('interfaces.tx_mtuerrors').alias('tx_mtuerrors'),\n",
    "                   col('interfaces.txcarrier_transition').alias('txcarrier_transition'),\n",
    "                   col('interfaces.tx_mcast_packets').alias('tx_mcast_packets'),\n",
    "                   col('interfaces.tx_bcast_packets').alias('tx_bcast_packets'),\n",
    "                   col('interfaces.rx_mcast_packets').alias('rx_mcast_packets'),\n",
    "                   col('interfaces.rx_bcast_packets').alias('rx_bcast_packets'),\n",
    "                   col('interfaces.rx_l3_incompletes').alias('rx_l3_incompletes'),\n",
    "                   col('interfaces.rx_l2_channel_error').alias('rx_l2_channel_error'),\n",
    "                   col('interfaces.rx_l2_mismatch_timeouts').alias('rx_l2_mismatch_timeouts'),\n",
    "                   col('interfaces.rx_fifo_errors').alias('rx_fifo_errors'),\n",
    "                   col('interfaces.rx_resource_errors').alias('rx_resource_errors'),\n",
    "                   col('interfaces.auto_negotiation_status').alias('auto_negotiation_status'),\n",
    "                   col('interfaces.media_type').alias('media_type'))\n",
    "\n",
    "vp_udf = udf(lambda x: 'phy' if (x[:2]=='ge') | (x[:2]=='xe') | (x[:2]=='et') else 'vir', StringType())\n",
    "dfin = dfin.withColumn('type', vp_udf('name'))\n",
    "\n",
    "dfin = dfin.filter(col('media_type')=='copper')\n",
    "\n",
    "convert_time = udf(lambda x: datetime.utcfromtimestamp(x/1000000).strftime('%Y-%m-%dT%H:%M:%S.%f+00:00')[:16], StringType())\n",
    "dfin = dfin.withColumn('time', convert_time('when'))\n",
    "\n",
    "dfin = dfin.filter(dfin.poe_power_limit>0)\n",
    "pct = udf(lambda x: x[0]/x[1], FloatType())\n",
    "dfin = dfin.withColumn('power_pct', pct(struct('poe_power','poe_power_limit')))\n",
    "\n",
    "dfin = dfin.filter(col('delta')==True)\n",
    "\n",
    "reix = udf(lambda x: int(x[3]), IntegerType())\n",
    "dfin = dfin.withColumn('re_ix', reix(dfin.name))\n",
    "\n",
    "dfin.write.parquet('s3://mist-data-science-dev/jing/switch/interfaces'+date)\n",
    "\n",
    "# Explode dflldp\n",
    "dflldp = df.select('id',\n",
    "                 'mac',\n",
    "                 'org_id',\n",
    "                 'site_id',\n",
    "                 'when',\n",
    "                 'remote_addr',\n",
    "                 'hostname',\n",
    "                 'model',\n",
    "                 'firmware_version',\n",
    "                 'serial_number',\n",
    "                 'stpbridge_protocol',\n",
    "                 'stpbridge_root_id',\n",
    "                 'stpbridge_root_cost',\n",
    "                 'stpbridge_root_port',\n",
    "                 'stpbridge_hello_time',\n",
    "                 'stpbridge_max_age',\n",
    "                 'stpbridge_forward_delay',\n",
    "                 'stpbridge_msg_age',\n",
    "                 'stpbridge_topo_chg_cnt',\n",
    "                 'stpbridge_last_topo_chg',\n",
    "                 'stpbridge_bridge_id',\n",
    "                 'uptime',\n",
    "                 'stats_delta',\n",
    "                 'delta',\n",
    "                 'deltaErrorMsg',\n",
    "                 'delta_interval',\n",
    "                 'poe_controller_module_index',\n",
    "                 'poe_controller_max_power',\n",
    "                 'poe_controller_consumption',\n",
    "                 'poe_controller_guardband',\n",
    "                 explode_outer('lldpneighbors').alias('lldp'))\n",
    "\n",
    "dflldp = dflldp.select('mac',\n",
    "                   'when',\n",
    "                   col('lldp.local_port_id').alias('local_port_id'),\n",
    "                   col('lldp.local_parent_iface_name').alias('local_parent_iface_name'),\n",
    "                       col('lldp.remote_chassis_id').alias('remote_chassis_id'),\n",
    "                       col('lldp.remote_chassis_idsubtype').alias('remote_chassis_idsubtype'),\n",
    "                       col('lldp.remote_port_desc').alias('remote_port_desc'),\n",
    "                       col('lldp.remote_system_name').alias('remote_system_name'),\n",
    "                       col('lldp.remote_mgmt_addr').alias('remote_mgmt_addr'),\n",
    "                       col('lldp.remote_system_desc').alias('remote_system_desc'),\n",
    "                       col('lldp.remote_mac').alias('remote_mac'),\n",
    "                       col('lldp.remote_vlan_id').alias('remote_vlan_id'),\n",
    "                       col('lldp.remote_hardware').alias('remote_hardware'),\n",
    "                       col('lldp.remote_serial').alias('remote_serial'),\n",
    "                       col('lldp.remote_manufacture').alias('remote_manufacture'),\n",
    "                       col('lldp.remote_system_capability').alias('remote_system_capability'))\n",
    "\n",
    "# don't need join re_ix as name has handle different chassis\n",
    "dflldp = dflldp.withColumnRenamed('mac','mac1') \\\n",
    "                .withColumnRenamed('when','when1') \n",
    "dfuplink = dfin.join(dflldp, (dfin.mac==dflldp.mac1)&(dfin.when==dflldp.when1)&(dfin.name==dflldp.local_port_id), 'left_outer') \\\n",
    "                .drop('mac1','when1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplink Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def uplink_lldp(df):\n",
    "#     if df.select('remote_hardware')[:2] == 'AP':\n",
    "#         return 0\n",
    "# #     if df.select('remote_hardware') == '...':\n",
    "# #         return True\n",
    "# #     else:\n",
    "# #         return False\n",
    "    \n",
    "# def uplink_speed(df):\n",
    "#     if df.select('mbps') > 1000: \n",
    "#         return True\n",
    "#     else: \n",
    "#         return False\n",
    "\n",
    "# def uplink_ae(df):\n",
    "#     if df.select('name') == 'ae':\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "    \n",
    "# def uplink_stp(df):\n",
    "#     if df.select('STPRole') == 'root':\n",
    "#         return True\n",
    "#     else: \n",
    "#         return False\n",
    "\n",
    "# def uplink_stproot(dfmac, name):\n",
    "#     if dfmac.filter(col('stpbridge_root_port')==name).count() > 0:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "    \n",
    "# def uplink_data(df, rxmax, txmax):\n",
    "#     if df.select('tx_packets') == txmax: \n",
    "#         return True\n",
    "#     elif df.select('rx_packets') == rxmax:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# def uplink(mac, module_index, name, time, df_in):\n",
    "#     df = df_in.filter(col('mac')==mac) \\\n",
    "#                 .filter(col('name')==name) \\\n",
    "#                 .filter(col('re_ix')==module_index) \\\n",
    "#                 .filter(col('time')==time)\n",
    "#     dfmac = df_in.filter(col('mac')==mac) \\\n",
    "#                 .filter(col('re_ix')==module_index) \\\n",
    "#                 .filter(col('time')==time)\n",
    "#     max_rxpkts = dfmac.agg(max_('rx_packets')).collect()[0]['max(rx_packets)'] \n",
    "#     max_txpkts = dfmac.agg(max_('tx_packets')).collect()[0]['max(tx_packets)']\n",
    "#     root = 0\n",
    "    \n",
    "#     # link is down, not root for sure\n",
    "#     if df.filter(col('link')==False):\n",
    "#         return 0\n",
    "    \n",
    "#     # firmly know it is not root\n",
    "#     if uplink_lldp(df) == 0:\n",
    "#         return 0\n",
    "    \n",
    "#     if uplink_lldp(df):\n",
    "#         root += 1\n",
    "\n",
    "#     if uplink_speed(df):\n",
    "#         root += 1\n",
    "        \n",
    "# #     if uplink_ae(df):\n",
    "# #         root += 1\n",
    "        \n",
    "# #     if uplink_stp(df):\n",
    "# #         root += 1\n",
    "\n",
    "#     if uplink_stproot(dfmac, name):\n",
    "#         root += 1\n",
    "    \n",
    "#     if uplink_data(df, max_rxpkts, max_txpkts):\n",
    "#         root += 1\n",
    "        \n",
    "#     return root\n",
    "\n",
    "# def __main__(dfuplink, time):\n",
    "#     dict_root = {}\n",
    "#     for each in dfuplink.filter(col('time')==time).select('mac'),'re_ix','name').distinct().collect():\n",
    "#         root = uplink(mac, re_ix, name, time, dfuplink)\n",
    "#         dict_root[each] = root\n",
    "    \n",
    "#     itemMaxValue = max(dict_root.items(), key=lambda x: x[1]) \n",
    "#     listOfKeys = list()\n",
    "#     for key, value in dict_root.items():\n",
    "#         if value == itemMaxValue[1]:\n",
    "#             listOfKeys.append(key)\n",
    "    \n",
    "#     return listOfKeys\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     __main__(dfuplink, time)\n",
    "#     # __main__(dfuplink, '0c8126c7054d',0, 'ge-0/0/1','2019-11-05T07:19')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_root(x):\n",
    "#     name = x[0]\n",
    "#     rxpkts = x[1]\n",
    "#     txpkts = x[2]\n",
    "#     bridgeroot = x[3][0]\n",
    "#     remotehw = x[4]\n",
    "#     mbps = x[5]\n",
    "#     remotecap = x[6]\n",
    "#     # stprole = x[7]\n",
    "#     d_root = {}\n",
    "    \n",
    "#     max_rxpkts = np.max(rxpkts)\n",
    "#     max_txpkts = np.max(txpkts)\n",
    "        \n",
    "#     for i in range(len(name)):\n",
    "        \n",
    "#         d_root.setdefault(name[i], 0)\n",
    "        \n",
    "#         # bridgeport\n",
    "#         if name[i] == bridgeroot: \n",
    "#             d_root[name[i]] += 1\n",
    "        \n",
    "#         # data packets\n",
    "#         if rxpkts[i] == max_rxpkts:\n",
    "#             d_root[name[i]] += 1\n",
    "#         elif txpkts[i] == max_txpkts:\n",
    "#             d_root[name[i]] += 1\n",
    "        \n",
    "#         # remote hardware \n",
    "#         if remotehw[i][:2] == 'AP':\n",
    "#             d_root[name[i]] == -100\n",
    "        \n",
    "#         # remote capability\n",
    "#         if remotecap[i] == 'Bridge Router':\n",
    "#             d_root[name[i]] += 1\n",
    "        \n",
    "#         # speed\n",
    "#         if mbps[i] > 1000:\n",
    "#             d_root[name[i]] += 1\n",
    "        \n",
    "# #         if name[i] == 'ae':\n",
    "# #             d_root[name[i]] += 1\n",
    "    \n",
    "# #         if stprole[i] == 'root':\n",
    "# #             d_root[name[i]] += 1\n",
    "    \n",
    "#     itemMaxValue = max(d_root.items(), key=lambda x: x[1]) \n",
    "#     listOfKeys = list()\n",
    "#     for key, value in d_root.items():\n",
    "#         if value == itemMaxValue[1]:\n",
    "#             listOfKeys.append(key)\n",
    "        \n",
    "#     return listOfKeys\n",
    "\n",
    "# def __main__(dfuplink, mac, re_ix, name, time):\n",
    "\n",
    "#     df = dfuplink.filter(col('mac')==mac) \\\n",
    "#                 .filter(col('re_ix')==module_index) \\\n",
    "#                 .filter(col('time')==time) \\\n",
    "#                 .filter(col('link')==True)\n",
    "\n",
    "#     df = df.groupby('mac','re_ix','time').agg(collect_list('name').alias('lst_name'), \\\n",
    "#                                              collect_list('rx_packets').alias('lst_rxpkts'), \\\n",
    "#                                               collect_list('tx_packets').alias('lst_txpkts'), \\\n",
    "#                                               collect_list('stpbridge_root_port').alias('lst_bridgeroot'), \\\n",
    "#                                               collect_list('remote_hardware').alias('lst_remotehw'), \\\n",
    "#                                               collect_list('mbps').alias('lst_mbps'))\n",
    "#     get_root_udf = udf(get_root, ArrayType(StringType()))\n",
    "#     df = df.withColumn('root', get_root_udf(struct('lst_name','lst_rxpkts','lst_txpkts','lst_bridgeroot','lst_remotehw','lst_mbps')))\n",
    "    \n",
    "# if __name__==\"__main__\":\n",
    "#     __main__(dfuplink, mac, re_ix, name, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each root\n",
    "def bridge(x):\n",
    "    if x[0] == x[1]: return 1\n",
    "    else: return 0\n",
    "\n",
    "def pkts(x): \n",
    "    import copy\n",
    "    rx = x[0]\n",
    "    tx = x[1]\n",
    "    port = x[2]\n",
    "    root = set()\n",
    "    for i in range(len(rx)):\n",
    "        temp = copy.deepcopy(tx)\n",
    "        temp.pop(i)\n",
    "        if all(rx[i] > t for t in temp):\n",
    "            root.add(port[i])\n",
    "    for i in range(len(rx)):\n",
    "        temp = copy.deepcopy(rx)\n",
    "        temp.pop(i)\n",
    "        if all(tx[i] > t for t in temp):\n",
    "            root.add(port[i])        \n",
    "    return list(root)\n",
    "    \n",
    "def remotehw(x):\n",
    "    if x[:2] == 'AP': return 0\n",
    "    else: return 1\n",
    "\n",
    "def remotecap(x):\n",
    "    if x == 'Bridge Router': return 1\n",
    "    else: return 0\n",
    "    \n",
    "def mbps(x):\n",
    "    if x > 1000: return 1\n",
    "    else: return 0\n",
    "\n",
    "bridge_udf = udf(bridge, IntegerType())\n",
    "pkts_udf = udf(pkts, ArrayType(StringType()))\n",
    "remotehw_udf = udf(remotehw, IntegerType())\n",
    "remotecap_udf = udf(remotecap, IntegerType())\n",
    "mbps_udf = udf(mbps, IntegerType())\n",
    "\n",
    "# Get root from pkts logic\n",
    "dfpkts = dfuplink.groupby('mac','re_ix','time').agg(collect_list('rx_packets').alias('lst_rxpkts'), \\\n",
    "                                                    collect_list('tx_packets').alias('lst_txpkts'), \n",
    "                                                    collect_list('name').alias('lst_port'))\n",
    "dfpkts = dfpkts.withColumn('rootpkts', pkts_udf(struct('lst_rxpkts','lst_txpkts','lst_port'))) \\\n",
    "                .withColumnRenamed('mac','mac1') \\\n",
    "                .withColumnRenamed('re_ix','re_ix1') \\\n",
    "                .withColumnRenamed('time','time1') \\\n",
    "                .drop('lst_txpkts','lst_rxpkts','lst_port')\n",
    "\n",
    "dfpkts = dfpkts.select('*', explode('rootpkts').alias('pkts1')).drop('rootpkts')\n",
    "                           \n",
    "dffull = dfuplink.join(dfpkts, (dfuplink.mac==dfpkts.mac1)&(dfuplink.re_ix==dfpkts.re_ix1)&(dfuplink.time==dfpkts.time1), 'left') \\\n",
    "                    .drop('mac1','re_ix1','time1')\n",
    "\n",
    "rootpkts = udf(lambda x: 1 if x[0]==x[1] else 0, IntegerType())  \n",
    "dffull = dffull.withColumn('pkts', rootpkts(struct('name','pkts1')))  \n",
    "\n",
    "# Get root from other logics, filter out remotehw = AP\n",
    "dffull = dffull.fillna(' ')\n",
    "dffull = dffull.filter(dffull.remotehw==1)\n",
    "dfroot = dffull.withColumn('remotecap', remotecap_udf('remote_system_capability')) \\\n",
    "                .withColumn('rmbps', mbps_udf('mbps')) \\\n",
    "                .withColumn('remotehw', remotehw_udf('remote_hardware')) \\\n",
    "                .withColumn('bridge', bridge_udf(struct('stpbridge_root_port','name'))) \\\n",
    "                .select('mac','site_id','time','re_ix','name','remotecap','rmbps','bridge','pkts')\n",
    "\n",
    "# =========================================\n",
    "# Modeling\n",
    "pdf = dfroot.select('mac','re_ix','name','remotecap','rmbps','bridge','pkts').distinct().toPandas()\n",
    "          \n",
    "# Labeling: \n",
    "# 0c8126c71290: ge-0/0/1 0\n",
    "# 1c9c8cba2e7f: ge-0/0/1 0\n",
    "# 1c9c8cba2d44: ge-0/0/4 0\n",
    "# 1c9c8cba2d44: ge-1/0/5 1\n",
    "# 0256: ge-0/0/0 ?\n",
    "# 80acacf2f530: ge-0/0/0 0\n",
    "# 3c8c939495ac: ge-0/0/8 0\n",
    "# 0c8126c70665: ge-0/0/10 0\n",
    "# d8b12288af4f: ge-0/0/0 0\n",
    "# 1c9c8cba2970: ge-0/0/4 and ge-0/0/5 0\n",
    "\n",
    "label1 = [\n",
    "    ['1c8126c71290','ge-0/0/1',0],\n",
    "    ['1c9c8cba2e7f','ge-0/0/1',0],\n",
    "    ['1c9c8cba2d44','ge-0/0/4',0],\n",
    "    ['1c9c8cba2d44','ge-1/0/5',1],\n",
    "    ['80acacf2f530','ge-0/0/0',0],\n",
    "    ['3c8c939495ac','ge-0/0/8',0],\n",
    "    ['0c8126c70665','ge-0/0/10',0],\n",
    "    ['d8b12288af4f','ge-0/0/0',0],\n",
    "    ['1c9c8cba2970','ge-0/0/4',0],\n",
    "    ['1c9c8cba2970','ge-0/0/5',0]\n",
    "]\n",
    "\n",
    "# Get the mac which has labels\n",
    "flag = True\n",
    "for each in label1:\n",
    "    if flag:\n",
    "        pdf1 = pdf[(pdf.mac==each[0])&(pdf.re_ix==each[2])]\n",
    "        flag = False\n",
    "    else:\n",
    "        pdf0 = pdf[(pdf.mac==each[0])&(pdf.re_ix==each[2])]\n",
    "        pdf1 = pd.concat([pdf0, pdf1], axis=0)\n",
    "\n",
    "# def get_label(mac, re_ix, name):\n",
    "#     flag = 0\n",
    "#     for each in label1:    \n",
    "#         if (mac==each[0])&(name==each[1])&(re_ix==each[2]):\n",
    "#             flag = 1\n",
    "#     return flag\n",
    "     \n",
    "# pdf1['label'] = pdf1.apply(lambda r: get_label(r.mac, r.re_ix, r.name), axis=1)\n",
    "                                   \n",
    "for ix, row in pdf1.iterrows():\n",
    "    for each in label1:\n",
    "        if (row['mac']==each[0])&(row['name']==each[1])&(row['re_ix']==each[2]):\n",
    "            pdf1.at[ix,'label'] = 1\n",
    "pdf1 = pdf1.fillna(0)\n",
    "\n",
    "# Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = pdf1[['remotecap','rmbps','bridge','pkts']]\n",
    "y = pdf1['label']\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                          multi_class='multinomial')\n",
    "clf = model.fit(X, y)\n",
    "clf.score(X, y)  #0.87\n",
    "clf.predict(X)\n",
    "\n",
    "In [157]: model.coef_                                                                                                                          \n",
    "Out[157]: array([[1.01196051, 0.        , 1.37810952, 0.52740574]])\n",
    "In [158]: model.intercept_                                                                                                                     \n",
    "Out[158]: array([-1.38771024])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# base = dfroot.select('mac','re_ix','name','time').distinct()\n",
    "# dfroot1 = dfroot.filter(col('remotehw')==1) \\\n",
    "#                 .filter(col('maxrxpkts')>0) \\\n",
    "#                 .filter(col('maxtxpkts')>0) \\\n",
    "#                 .filter((col('remotecap')>0)|(col('bridge')>0)|(col('pkts')>0)|(col('rmbps')>0)) \\\n",
    "#                 .select('mac','re_ix','name','time','remotecap','bridge','pkts','rmbps') \\\n",
    "#                 .withColumnRenamed('mac','mac1') \\\n",
    "#                 .withColumnRenamed('re_ix','re_ix1') \\\n",
    "#                 .withColumnRenamed('name','name1') \\\n",
    "#                 .withColumnRenamed('time','time1')\n",
    "\n",
    "\n",
    "# dfjoin = base.join(dfroot1, (base.mac==dfroot1.mac1)&(base.re_ix==dfroot1.re_ix1)&(base.name==dfroot1.name1)&(base.time==dfroot1.time1), 'left') \\\n",
    "#                 .drop('mac1','re_ix1','name1','time1')\n",
    "\n",
    "# dfjoin = dfjoin.fillna(0)\n",
    "\n",
    "# sumudf = udf(lambda x: x[0]+x[1]+x[2]+x[3], IntegerType())\n",
    "# df0 = dfjoin.withColumn('root', sumudf(struct('remotecap','bridge','pkts','rmbps')))\n",
    "# df1 = df0.groupby('mac','re_ix','name').agg(sum_('root').alias('sumroot'))\n",
    "# df2 = df1.filter(df1.sumroot>0)\n",
    "# df2 = df2.withColumnRenamed('mac','mac1') \\\n",
    "#             .withColumnRenamed('re_ix','re_ix1') \\\n",
    "#             .withColumnRenamed('name','name1') \n",
    "\n",
    "# dffinal = dfjoin.join(df2, (dfjoin.mac==df2.mac1)&(dfjoin.re_ix==df2.re_ix1)&(dfjoin.name==df2.name1), 'inner') \\\n",
    "#                 .drop('mac1','re_ix1','name1','sumroot')\n",
    "\n",
    "# dffinal.toPandas().to_csv('uplink.csv')                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Old logic for pkts\n",
    "# # Get each root\n",
    "# def bridge(x):\n",
    "#     if x[0] == x[1]: return 1\n",
    "#     else: return 0\n",
    "\n",
    "# def pkts(x): \n",
    "#     if x[0] == x[2]: return 1\n",
    "#     elif x[1] == x[3]: return 1\n",
    "#     else: return 0\n",
    "    \n",
    "# def remotehw(x):\n",
    "#     if x[:2] == 'AP': return 0\n",
    "#     else: return 1\n",
    "\n",
    "# def remotecap(x):\n",
    "#     if x == 'Bridge Router': return 1\n",
    "#     else: return 0\n",
    "    \n",
    "# def mbps(x):\n",
    "#     if x > 1000: return 1\n",
    "#     else: return 0\n",
    "\n",
    "# bridge_udf = udf(bridge, IntegerType())\n",
    "# pkts_udf = udf(pkts, IntegerType())\n",
    "# remotehw_udf = udf(remotehw, IntegerType())\n",
    "# remotecap_udf = udf(remotecap, IntegerType())\n",
    "# mbps_udf = udf(mbps, IntegerType())\n",
    "\n",
    "# dfmac = dfuplink.groupby('mac','re_ix','time').agg(max_('rx_packets').alias('maxrxpkts'), max_('tx_packets').alias('maxtxpkts')) \\\n",
    "#                 .withColumnRenamed('mac','mac1') \\\n",
    "#                 .withColumnRenamed('re_ix','re_ix1') \\\n",
    "#                 .withColumnRenamed('time','time1')\n",
    "# dffull = dfuplink.join(dfmac, (dfuplink.mac==dfmac.mac1)&(dfuplink.re_ix==dfmac.re_ix1)&(dfuplink.time==dfmac.time1), 'left') \\\n",
    "#                     .drop('mac1','re_ix1','time1')\n",
    "\n",
    "# dffull = dffull.fillna(' ')\n",
    "# dfroot = dffull.withColumn('remotecap', remotecap_udf('remote_system_capability')) \\\n",
    "#                 .withColumn('rmbps', mbps_udf('mbps')) \\\n",
    "#                 .withColumn('remotehw', remotehw_udf('remote_hardware')) \\\n",
    "#                 .withColumn('bridge', bridge_udf(struct('stpbridge_root_port','name'))) \\\n",
    "#                 .withColumn('pkts', pkts_udf(struct('rx_packets','maxrxpkts','tx_packets','maxtxpkts')))\n",
    "\n",
    "# base = dfroot.select('mac','re_ix','name','time').distinct()\n",
    "# dfroot1 = dfroot.filter(col('remotehw')==1) \\\n",
    "#                 .filter(col('maxrxpkts')>0) \\\n",
    "#                 .filter(col('maxtxpkts')>0) \\\n",
    "#                 .filter((col('remotecap')>0)|(col('bridge')>0)|(col('pkts')>0)|(col('rmbps')>0)) \\\n",
    "#                 .select('mac','re_ix','name','time','remotecap','bridge','pkts','rmbps') \\\n",
    "#                 .withColumnRenamed('mac','mac1') \\\n",
    "#                 .withColumnRenamed('re_ix','re_ix1') \\\n",
    "#                 .withColumnRenamed('name','name1') \\\n",
    "#                 .withColumnRenamed('time','time1')\n",
    "\n",
    "\n",
    "# dfjoin = base.join(dfroot1, (base.mac==dfroot1.mac1)&(base.re_ix==dfroot1.re_ix1)&(base.name==dfroot1.name1)&(base.time==dfroot1.time1), 'left') \\\n",
    "#                 .drop('mac1','re_ix1','name1','time1')\n",
    "\n",
    "# dfjoin = dfjoin.fillna(0)\n",
    "\n",
    "# sumudf = udf(lambda x: x[0]+x[1]+x[2]+x[3], IntegerType())\n",
    "# df0 = dfjoin.withColumn('root', sumudf(struct('remotecap','bridge','pkts','rmbps')))\n",
    "# df1 = df0.groupby('mac','re_ix','name').agg(sum_('root').alias('sumroot'))\n",
    "# df2 = df1.filter(df1.sumroot>0)\n",
    "# df2 = df2.withColumnRenamed('mac','mac1') \\\n",
    "#             .withColumnRenamed('re_ix','re_ix1') \\\n",
    "#             .withColumnRenamed('name','name1') \n",
    "\n",
    "# dffinal = dfjoin.join(df2, (dfjoin.mac==df2.mac1)&(dfjoin.re_ix==df2.re_ix1)&(dfjoin.name==df2.name1), 'inner') \\\n",
    "#                 .drop('mac1','re_ix1','name1','sumroot')\n",
    "\n",
    "# dffinal.toPandas().to_csv('uplink.csv')                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --END--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

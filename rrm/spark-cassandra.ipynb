{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Can not load class com.mist.spark.udf.CmapCount, please make sure it is on the classpath;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/mistsys/ds_incubator/venv/spark-2.4.4-bin-without-hadoop/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mistsys/ds_incubator/venv/spark-2.4.4-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o29.registerJava.\n: org.apache.spark.sql.AnalysisException: Can not load class com.mist.spark.udf.CmapCount, please make sure it is on the classpath;\n\tat org.apache.spark.sql.UDFRegistration.registerJava(UDFRegistration.scala:661)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abbf4d7ddaa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cluster_a/spark.cassandra.connection.host\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cassandra-v3-000-production.mist.pvt,cassandra-v3-001-production.mist.pvt,cassandra-v3-002-production.mist.pvt,cassandra-v3-003-production.mist.pvt,cassandra-v3-004-production.mist.pvt,cassandra-v3-005-production.mist.pvt,cassandra-v3-006-production.mist.pvt,cassandra-v3-007-production.mist.pvt,cassandra-v3-008-production.mist.pvt,cassandra-v3-009-production.mist.pvt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cluster_b/spark.cassandra.connection.host\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cassandra-capacity-000-production.mist.pvt,cassandra-capacity-001-production.mist.pvt,cassandra-capacity-002-production.mist.pvt,cassandra-capacity-003-production.mist.pvt,cassandra-capacity-004-production.mist.pvt,cassandra-capacity-005-production.mist.pvt,cassandra-capacity-006-production.mist.pvt,cassandra-capacity-007-production.mist.pvt,cassandra-capacity-008-production.mist.pvt,cassandra-capacity-009-production.mist.pvt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregisterJavaFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cmaps_count\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"com.mist.spark.udf.CmapCount\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIntegerType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mload_options_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"cluster_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"table\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"capacity_classifier_trend_hist_by_ap_1h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keyspace\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sle_capacity\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mload_options_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"cluster_b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"table\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"capacity_classifier_trend_hist_by_ap_1h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keyspace\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sle_capacity\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mistsys/ds_incubator/venv/spark-2.4.4-bin-without-hadoop/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36mregisterJavaFunction\u001b[0;34m(self, name, javaClassName, returnType)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mreturnType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_datatype_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mjdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregisterJava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjavaClassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mistsys/ds_incubator/venv/spark-2.4.4-bin-without-hadoop/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mistsys/ds_incubator/venv/spark-2.4.4-bin-without-hadoop/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Can not load class com.mist.spark.udf.CmapCount, please make sure it is on the classpath;'"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession, udf\n",
    "from pyspark.sql.functions import date_format, coalesce\n",
    "from pyspark.sql.types import IntegerType\n",
    "spark = SparkSession.builder.appName(\"Spark sle_capacitycapacity_classifier_trend_hist_by_ap_1h\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "spark.conf.set(\"cluster_a/spark.cassandra.connection.host\", \"cassandra-v3-000-production.mist.pvt,cassandra-v3-001-production.mist.pvt,cassandra-v3-002-production.mist.pvt,cassandra-v3-003-production.mist.pvt,cassandra-v3-004-production.mist.pvt,cassandra-v3-005-production.mist.pvt,cassandra-v3-006-production.mist.pvt,cassandra-v3-007-production.mist.pvt,cassandra-v3-008-production.mist.pvt,cassandra-v3-009-production.mist.pvt\")\n",
    "spark.conf.set(\"cluster_b/spark.cassandra.connection.host\", \"cassandra-capacity-000-production.mist.pvt,cassandra-capacity-001-production.mist.pvt,cassandra-capacity-002-production.mist.pvt,cassandra-capacity-003-production.mist.pvt,cassandra-capacity-004-production.mist.pvt,cassandra-capacity-005-production.mist.pvt,cassandra-capacity-006-production.mist.pvt,cassandra-capacity-007-production.mist.pvt,cassandra-capacity-008-production.mist.pvt,cassandra-capacity-009-production.mist.pvt\")\n",
    "spark.udf.registerJavaFunction(\"cmaps_count\",\"com.mist.spark.udf.CmapCount\",IntegerType())\n",
    "load_options_a = {\"cluster\": \"cluster_a\", \"table\": \"capacity_classifier_trend_hist_by_ap_1h\", \"keyspace\": \"sle_capacity\"}\n",
    "load_options_b = {\"cluster\": \"cluster_b\", \"table\": \"capacity_classifier_trend_hist_by_ap_1h\", \"keyspace\": \"sle_capacity\"}\n",
    "df_a = spark.read.format(\"org.apache.spark.sql.cassandra\").options(**load_options_a).load()\n",
    "df_b = spark.read.format(\"org.apache.spark.sql.cassandra\").options(**load_options_b).load()\n",
    "df_a.createOrReplaceTempView(\"table_a\")\n",
    "df_b.createOrReplaceTempView(\"table_b\")\n",
    "sql_cmd = \"SELECT a.`ap_mac` as `ap_mac_a`, b.`ap_mac` as `ap_mac_b`,a.`classifier` as `classifier_a`, b.`classifier` as `classifier_b`,a.`fail` as `fail_a`, b.`fail` as `fail_b`,a.`org_id` as `org_id_a`, b.`org_id` as `org_id_b`,a.`rt` as `rt_a`, b.`rt` as `rt_b`,a.`site_id` as `site_id_a`, b.`site_id` as `site_id_b`,a.`success` as `success_a`, b.`success` as `success_b`,a.`val_avg` as `val_avg_a`, b.`val_avg` as `val_avg_b`,a.`val_avg__count` as `val_avg__count_a`, b.`val_avg__count` as `val_avg__count_b`,a.`val_hist` as `val_hist_a`, b.`val_hist` as `val_hist_b`  FROM (SELECT ap_mac,classifier,fail,org_id,rt,site_id,success,val_avg,val_avg__count,val_hist, hash(`classifier`,`fail`,`org_id`,`success`,`val_avg`,`val_avg__count`,`val_hist`) as hash_a  FROM table_a WHERE rt>=to_timestamp('2020-02-29 10:00:00', 'yyyy-MM-dd HH:mm:ss') and  rt<=to_timestamp('2020-02-29 22:00:00', 'yyyy-MM-dd HH:mm:ss')  ) as a FULL OUTER JOIN (SELECT ap_mac,classifier,fail,org_id,rt,site_id,success,val_avg,val_avg__count,val_hist, hash(`classifier`,`fail`,`org_id`,`success`,`val_avg`,`val_avg__count`,`val_hist`) as hash_b  FROM table_b WHERE rt>=to_timestamp('2020-02-29 10:00:00', 'yyyy-MM-dd HH:mm:ss') and  rt<=to_timestamp('2020-02-29 22:00:00', 'yyyy-MM-dd HH:mm:ss')  ) as b  ON   a.ap_mac =  b.ap_mac AND   a.rt =  b.rt AND   a.site_id =  b.site_id WHERE 1=1 AND NOT (a.hash_a = b.hash_b)   OR a.rt is null OR b.rt is null\"\n",
    "mistmatch_result = spark.sql(sql_cmd.strip())\n",
    "mistmatch_result.createOrReplaceTempView(\"mistmatch_result\")\n",
    "mistmatch_result.withColumn(\"dt\", date_format(coalesce(mistmatch_result.rt_a,mistmatch_result.rt_b), \"yyyyMMddHHmmss\")).repartition(1, \"dt\").write.partitionBy(\"dt\").mode(\"overwrite\").parquet(\"s3://mist-cassrator-production/sle_capacity.db/capacity_classifier_trend_hist_by_ap_1h\")\n",
    "load_options_records_count = {\"cluster\": \"cluster_b\", \"table\": \"records_count\", \"keyspace\": \"biloba\"}\n",
    "spark.sql(\"with m as (select coalesce(rt_a,rt_b) as rt, sum(case when rt_a is null then 0 else 1 end) as mistmatch_a, sum(case when rt_b is null then 0 else 1 end) as mistmatch_b, count(*) mistmatch_total from mistmatch_result group by rt ), a as (select rt, count(*) as record_count_a from table_a group by rt), b as (select rt, count(*) as record_count_b from table_b group by rt) select keyspace_name, table_name, coalesce(t.rt,m.rt) as rt, record_count_a, record_count_b, mistmatch_a, mistmatch_b, mistmatch_total from (select 'sle_capacity' as keyspace_name, 'capacity_classifier_trend_hist_by_ap_1h' as table_name, coalesce(a.rt,b.rt) as rt, coalesce(a.record_count_a,0) as record_count_a, coalesce(b.record_count_b,0) as record_count_b from a full outer join b on a.rt = b.rt) t full outer join m on t.rt = m.rt  \").write.format(\"org.apache.spark.sql.cassandra\").mode(\"append\").options(**load_options_records_count).save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

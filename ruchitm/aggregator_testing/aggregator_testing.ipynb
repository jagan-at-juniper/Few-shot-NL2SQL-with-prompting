{"metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": "python"}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "file_extension": ".py", "pygments_lexer": "python3"}, "toc": {"nav_menu": {"width": "212px", "height": "77px"}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "base_numbering": 1, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "sc.addPyFile(<path_to_spark_jobs_zip>)\n# sc.addPyFile(\"s3://mist-data-science-dev/ruchitm/spark_testing/spark_jobs_ruchit_stacktrace.zip\")\n\nimport logging\nimport os\nimport pandas as pd\nimport random\nfrom datetime import datetime\n\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import *\nfrom common import epoch2datetime\nfrom analytics.utils.time_util import current_epoch_seconds, to_seconds, to_milliseconds\nfrom analytics.jobs.utils import *\nfrom analytics.data_access.utils import parse_search_results\n\nudf_datetime = F.udf(datetime.fromtimestamp, TimestampType())\n", "metadata": {"ExecuteTime": {"start_time": "2021-09-29T23:01:07.087648Z", "end_time": "2021-09-29T23:01:30.357061Z"}, "trusted": true}, "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"cell_type": "markdown", "source": "### Data extract and job execute", "metadata": {}}, {"cell_type": "code", "source": "date = '2022-06-21'\nstart_seconds = int((datetime.strptime(date, '%Y-%m-%d')-datetime(1970,1,1)).total_seconds())\ndebug = True\nfor i in range(2): # runs for 24 hours duration\n    start_time = start_seconds + 3600 * i + 1\n    end_time = start_time + 3600 - 1    \n    \n    job = stats_aggregator_job(start_time, end_time,\n                               \"es-client-event\",\n                               spark, \"staging\", debug_mode=debug)\n    job.config['fs_bucket'] = 'mist-data-science-dev'\n    job.config['path'] = f\"ruchitm/spark_testing/aggregated_stats_{'production' if debug else 'staging'}/\"\n    if not job.data_source_inst: continue\n    data = job.data_source_inst.get_data()\n    \n    category='mist_universe'\n    job.process_category(category, data)", "metadata": {"ExecuteTime": {"start_time": "2021-08-11T16:52:13.723076Z", "end_time": "2021-08-11T16:54:29.995338Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Check output", "metadata": {}}, {"cell_type": "code", "source": "date = '2022-06-21'\nhour = \"*\"\nprefix = f\"s3://mist-data-science-dev/ruchitm/spark_testing/aggregated_stats_production/mist_fast_roaming_failure_stats/\"\ndf_features = spark.read.parquet(prefix+f\"dt={date}/hr={hour}\")\n\ndf_features.printSchema()\ndf_features_pd = df_features.toPandas()", "metadata": {"ExecuteTime": {"start_time": "2021-08-16T20:45:36.143973Z", "end_time": "2021-08-16T20:45:53.447493Z"}, "trusted": true}, "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"name": "stdout", "text": "root\n |-- org_id: string (nullable = true)\n |-- timestamp: integer (nullable = true)\n |-- failure_count: long (nullable = true)\n |-- stats_agg_time: integer (nullable = true)", "output_type": "stream"}]}, {"cell_type": "code", "source": "df_features_pd", "metadata": {"ExecuteTime": {"start_time": "2021-08-16T20:45:53.449259Z", "end_time": "2021-08-16T20:45:53.476084Z"}, "trusted": true}, "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"name": "stdout", "text": "                                    org_id  ...  stats_agg_time\n0     5a578f3c-f094-4d13-a7dd-96f0aaecb5b6  ...      1655769601\n1     08e62572-70b1-4405-978e-80220f1bae65  ...      1655769601\n2     c1cac1c4-1753-4dde-a065-e17a1c305c2d  ...      1655769601\n3     f5451dc6-aa80-4d1c-a49a-dede30b6d878  ...      1655769601\n4     a023919c-d30a-4e79-bbd9-135bd68f22c6  ...      1655769601\n...                                    ...  ...             ...\n3010  a8b71182-9234-4af8-9aec-8fb7896db8aa  ...      1655773201\n3011  20b89a2d-ea17-4859-a685-c3125dc32b50  ...      1655773201\n3012  bef2f6b3-dffb-44a4-84d9-9f7132e6fa40  ...      1655773201\n3013  6ec2e3e5-ea6c-4da3-a04d-c22a0658994f  ...      1655773201\n3014  15b211e7-e46e-4b05-8015-dd3fffc11ca3  ...      1655773201\n\n[3015 rows x 4 columns]", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}
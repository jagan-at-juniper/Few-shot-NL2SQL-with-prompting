{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edac946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from functools import partial\n",
    "import math\n",
    "import ipaddress\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def round_datetime(timestamp, min_interval=0, sec_interval=0):\n",
    "    if timestamp : \n",
    "        timestamp = int(timestamp)\n",
    "    else :\n",
    "        timestamp=0\n",
    "    ## scaling timestamp to seconds resolution\n",
    "    scale=1\n",
    "    resolution = int(math.log10(timestamp))\n",
    "    if resolution==12:\n",
    "        scale=1E3\n",
    "    elif resolution==15:\n",
    "        scale=1E6\n",
    "    elif resolution==18:\n",
    "        scale=1E9\n",
    "    timestamp = timestamp//scale\n",
    "    tm = datetime.fromtimestamp(timestamp)\n",
    "    if min_interval > 0 and sec_interval > 0:\n",
    "        tm = tm - timedelta(minutes=tm.minute % min_interval, seconds=tm.second % sec_interval)\n",
    "    elif min_interval > 0 :\n",
    "        tm = tm - timedelta(minutes=tm.minute % min_interval, seconds=tm.second)\n",
    "    elif sec_interval > 0 :\n",
    "        tm = tm - timedelta(minutes=tm.minute, seconds=tm.second % sec_interval)\n",
    "    return tm\n",
    "\n",
    "def date_list(endDate, delta=14):\n",
    "    temp=[endDate]\n",
    "    for i in range(1,delta+1):\n",
    "        temp.append(endDate - timedelta(days=i))\n",
    "    return '{' + ','.join([str(d.date()) for d in temp]) + '}'\n",
    "\n",
    "\n",
    "udf_rounddate = F.udf(round_datetime, TimestampType())\n",
    "\n",
    "def getDateString(dates):\n",
    "    if ',' not in dates:\n",
    "        return dates.split('{')[1].split('}')[0]\n",
    "    else:\n",
    "        return dates.split('{')[1].split(',')[0] + \"_\" + dates.split('{')[1].split(',')[-1].split('}')[0]\n",
    "\n",
    "def get_ssr_app_ids(env):\n",
    "    PAPI_URL = 'http://papi-internal-{}.mist.pvt/internal/const/ssr_app_ids?format=json'\n",
    "    papi_url = PAPI_URL.format(env)\n",
    "    res = requests.get(papi_url)\n",
    "\n",
    "    if res.status_code != 200:\n",
    "        raise Exception(\n",
    "            'Fail to get app sle application thresholds from PAPI:{}: {}'.format(res.status_code,\n",
    "                                                                                 res.text))\n",
    "    return res.json()\n",
    "############################################################\n",
    "\n",
    "# endDate = datetime.today()\n",
    "endDate = datetime.strptime('2022-04-26', \"%Y-%m-%d\")\n",
    "interval = 1\n",
    "dates=date_list(endDate, delta=interval)\n",
    "date_string = getDateString(dates)\n",
    "hour = '{*}'\n",
    "hour_string = re.split('\\{|\\}', hour)[1]\n",
    "if hour_string==\"*\":\n",
    "    hour_string = \"all\"\n",
    "print(date_string, '', hour)\n",
    "storage = 's3'\n",
    "env = 'production'\n",
    "local = False\n",
    "sle_path = 'cv-sle-app-health'\n",
    "appsum_path = 'ssr-application-summary-analytics'\n",
    "\n",
    "df_org = spark.read.parquet(f\"{storage}://mist-secorapp-{env}/dimension/org/*.parquet\")\n",
    "df_site = spark.read.parquet(f\"{storage}://mist-secorapp-{env}/dimension/site/*.parquet\")\n",
    "\n",
    "df_app_thresholds = pd.DataFrame(get_ssr_app_ids(env))\n",
    "df_app_thresholds = pd.concat([df_app_thresholds, df_app_thresholds._sle_threshold.transform(pd.Series)], axis=1)\n",
    "CURATED_APPS = df_app_thresholds.device_app_name.unique()\n",
    "CURATED_APPS = [x.lower() for x in CURATED_APPS]\n",
    "print(CURATED_APPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5303a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_S3_data(path, dates, hour, env='staging', storage='s3', filtering=True, local=False):\n",
    "    \n",
    "    S3Filepath = f\"{storage}://mist-secorapp-{env}/{path}{'-local' if local else ''}/{path}-{env}/dt={dates}/hr={hour}\"\n",
    "    print(f\"{S3Filepath=}\")\n",
    "\n",
    "    if 'cv-sle-app-health'==path:\n",
    "\n",
    "        info_cols = [\"time\",\"site_id\",\"switch_mac\",\"switch_version\",\n",
    "                     \"device_app_name\", \"app_name\", \"client\", \"client_wcid\",\n",
    "                     \"category\", \"classifier_reason\", \"classifier\",\n",
    "                     \"interface_name\",\"custom\",\"internal_flags\",\"org_id\",\n",
    "                     \"traffic_class\"]\n",
    "\n",
    "        wan_metrics_cols = [\"latency\", \"jitter\", \"loss\"]\n",
    "        app_metrics_cols = [\"tx_tcp_retransmission_packets\", \"tx_tcp_reset\",\n",
    "                            \"tx_packets\", \"tx_bytes\",\n",
    "                            \"rx_tcp_retransmission_packets\", \"rx_tcp_reset\",\n",
    "                            \"rx_packets\", \"rx_bytes\",\n",
    "                            \"time_to_first_packet\",\"session_length\"]\n",
    "        df = spark.read.orc(S3Filepath)\n",
    "#         df.printSchema()\n",
    "        df = df.filter((F.col('switch_model').startswith('SSR')))\n",
    "        if filtering:\n",
    "            cols = info_cols + wan_metrics_cols + app_metrics_cols\n",
    "            df = df.select(cols)\n",
    "\n",
    "\n",
    "    elif 'ssr-application-summary-analytics'==path:\n",
    "        info_cols = [\"when\", \"site_id\", \"mac\", \"src_address\",\n",
    "                     \"device_app_name\", \"app_key\", \"app_summary_type\",\n",
    "                     \"category\", \"egress_network_interface\",\n",
    "                     \"custom_app\", \"org_id\", \"traffic_class\", \n",
    "                     \"protocol\", \"ingress_network_interface\"]\n",
    "\n",
    "        wan_metrics_cols = []\n",
    "        app_metrics_cols = [\"tcp_retransmission_packets_from_client\", \n",
    "                            \"tcp_reset_from_client\",\n",
    "                            \"packets_from_client\", \"bytes_from_client\",\n",
    "                            \"tcp_retransmission_packets_from_server\",\n",
    "                            \"tcp_reset_from_server\",\n",
    "                            \"packets_from_server\", \"bytes_from_server\",\n",
    "                            \"new_sessions\", \"active_sessions\",\n",
    "                            \"time_to_first_data_packet_avg\", \"session_length_avg\"]\n",
    "        \n",
    "        rename_dict = dict(zip([\"when\", \"mac\",\"src_address\", \"wcid\",\n",
    "                                \"egress_network_interface\", \"ingress_network_interface\",\n",
    "                                \"tcp_retransmission_packets_from_client\", \n",
    "                                \"tcp_reset_from_client\",\n",
    "                                \"packets_from_client\", \"bytes_from_client\",\n",
    "                                \"tcp_retransmission_packets_from_server\",\n",
    "                                \"tcp_reset_from_server\",\n",
    "                                \"packets_from_server\", \"bytes_from_server\",\n",
    "                               \"time_to_first_data_packet_avg\", \"session_length_avg\"], \n",
    "                              [\"time\", \"switch_mac\",\"client\", \"client_wcid\",\n",
    "                               \"interface_name\", \"ingress_interface_name\",\n",
    "                               \"tx_tcp_retransmission_packets\", \"tx_tcp_reset\",\n",
    "                                \"tx_packets\", \"tx_bytes\",\n",
    "                                \"rx_tcp_retransmission_packets\", \"rx_tcp_reset\",\n",
    "                                \"rx_packets\", \"rx_bytes\",\n",
    "                                \"time_to_first_packet\",\"session_length\"]))\n",
    "        df = spark.read.parquet(S3Filepath)\n",
    "        if filtering:\n",
    "            cols = info_cols + wan_metrics_cols + app_metrics_cols\n",
    "            df = df.select(cols)\n",
    "        for col in rename_dict:\n",
    "            df = df.withColumnRenamed(col, rename_dict[col])\n",
    "        df = df.withColumn('time', udf_rounddate('time'))\n",
    "\n",
    "    df = df.withColumn(\"hour\", (F.round(F.unix_timestamp(\"time\")/3600)*3600).cast(\"timestamp\"))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_curated_apps = False\n",
    "MIN_PACKETS = 10 # from app sle topology\n",
    "group_cols = ['switch_mac', 'device_app_name', 'hour', 'client']\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "df_sle =  get_S3_data(path=sle_path, dates=dates, hour=hour, env=env)\n",
    "df_sle = df_sle.withColumn('min_packets',\n",
    "                            F.when(F.greatest('rx_packets', 'tx_packets')<MIN_PACKETS, 1).otherwise(0))\n",
    "df_appsum =  get_S3_data(path=appsum_path, dates=dates, hour=hour, env=env)\n",
    "df_appsum = df_appsum.withColumn('min_packets',\n",
    "                                 F.when(F.greatest('rx_packets', 'tx_packets')<MIN_PACKETS, 1).otherwise(0))\n",
    "\n",
    "\n",
    "if filter_curated_apps:\n",
    "    df_sle = df_sle.filter(F.lower('device_app_name').isin(CURATED_APPS))\n",
    "    df_appsum = df_appsum.filter(F.lower('device_app_name').isin(CURATED_APPS))\n",
    "\n",
    "df_sle_count = df_sle.groupby(group_cols).agg(F.count('traffic_class').alias('count_sle'),\n",
    "                                                    F.sum('min_packets').alias('sum_sle_min_packets'))\n",
    "\n",
    "df_appsum_count = df_appsum.groupby(group_cols).agg(F.count('traffic_class').alias('count_appsum'),\n",
    "                                                    F.sum('min_packets').alias('sum_appsum_min_packets'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53feeea",
   "metadata": {},
   "source": [
    "### Analyze SLE missing and mismatches from App summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc96931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T18:57:54.408283Z",
     "start_time": "2022-04-29T18:53:28.819231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "sle_path = 'cv-sle-app-health'\n",
    "appsum_path = 'ssr-application-summary-analytics'\n",
    "inpath = f'{storage}://mist-data-science-dev/ruchitm'\n",
    "\n",
    "date_string = '2022-04-26_2022-04-25'\n",
    "env = 'production'\n",
    "group_cols = ['switch_mac', 'device_app_name', 'hour', 'client']\n",
    "\n",
    "filepath = f\"{inpath}/app-health-{env}/{sle_path}/agg_{'-'.join(group_cols)}/dt={date_string}/\"\n",
    "df_sle_pd = spark.read.parquet(filepath).toPandas()\n",
    "\n",
    "filepath = f\"{inpath}/app-health-{env}/{appsum_path}/agg_{'-'.join(group_cols)}/dt={date_string}/\"\n",
    "df_appsum_pd = spark.read.parquet(filepath).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb393332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:18:14.793728Z",
     "start_time": "2022-04-29T20:18:09.496370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_merge = pd.merge(df_sle_pd, df_appsum_pd, on=group_cols, how='outer')\n",
    "idx_time = (df_merge.hour>df_merge.hour.min()) & (df_merge.hour<df_merge.hour.max())\n",
    "df_merge = df_merge[idx_time].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9adfcb43-b3b3-4eff-84ed-22ccc4318800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:27:30.308141Z",
     "start_time": "2022-04-29T20:27:30.255222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 1262268\n",
      "SLE NaN count: 65201\n",
      "APPSUM NaN count: 0\n",
      "APPSUM record count: 32071581.0"
     ]
    }
   ],
   "source": [
    "df_merge['diff_appsum_sle'] = df_merge.count_appsum - df_merge.count_sle\n",
    "df_merge['diff_min_packets'] = df_merge.sum_appsum_min_packets - df_merge.sum_sle_min_packets\n",
    "\n",
    "print(f\"Total count: {df_merge.shape[0]}\")\n",
    "print(f\"SLE NaN count: {df_merge.count_sle.isna().sum()}\")\n",
    "print(f\"APPSUM NaN count: {df_merge.count_appsum.isna().sum()}\")\n",
    "\n",
    "TOTAL_APPSUM_RECORDS = df_merge['count_appsum'].sum()\n",
    "print(f\"APPSUM record count: {TOTAL_APPSUM_RECORDS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b235e18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:22:53.620634Z",
     "start_time": "2022-04-29T20:22:53.331906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLE missing:  3.182%\n",
      "SLE missing due to min packets:  3.182%\n",
      "SLE missing unexplained:  0.000%\n",
      "\n",
      " SLE missing unexplained\n",
      "       count_appsum  sum_appsum_min_packets\n",
      "count           0.0                     0.0\n",
      "mean            NaN                     NaN\n",
      "std             NaN                     NaN\n",
      "min             NaN                     NaN\n",
      "25%             NaN                     NaN\n",
      "50%             NaN                     NaN\n",
      "75%             NaN                     NaN\n",
      "max             NaN                     NaN"
     ]
    }
   ],
   "source": [
    "idx_sle_missing = (df_merge.count_sle.isna()) & (~df_merge.count_appsum.isna())\n",
    "print(f\"SLE missing: {df_merge[idx_sle_missing]['count_appsum'].sum()*100/TOTAL_APPSUM_RECORDS: .3f}%\")\n",
    "\n",
    "idx_missing_min_packets = (df_merge.count_appsum == df_merge.sum_appsum_min_packets) & idx_sle_missing\n",
    "print(f\"SLE missing due to min packets: {df_merge[idx_missing_min_packets]['count_appsum'].sum()*100/TOTAL_APPSUM_RECORDS: .3f}%\")\n",
    "\n",
    "idx_missing_other = ~(df_merge.count_appsum == df_merge.sum_appsum_min_packets) & idx_sle_missing\n",
    "print(f\"SLE missing unexplained: {df_merge[idx_missing_other]['count_appsum'].sum()*100/TOTAL_APPSUM_RECORDS: .3f}%\")\n",
    "print(\"\\n\",\"SLE missing unexplained\")\n",
    "df_merge[idx_missing_other][['count_appsum', 'sum_appsum_min_packets']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bad0b03-af87-4e73-97af-bd3906738e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:23:36.465278Z",
     "start_time": "2022-04-29T20:23:36.226924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLE mismatch:  4.8% \n",
      "\n",
      "count    64654.000000\n",
      "mean        11.831565\n",
      "std         17.547245\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          4.000000\n",
      "75%         13.000000\n",
      "max        148.000000\n",
      "Name: diff_appsum_sle, dtype: float64"
     ]
    }
   ],
   "source": [
    "idx_sle_mismatch = df_merge.diff_appsum_sle > 0.\n",
    "print(f\"SLE mismatch: {df_merge[idx_sle_mismatch]['count_appsum'].sum()*100/TOTAL_APPSUM_RECORDS: .1f}%\", \"\\n\")\n",
    "df_merge[idx_sle_mismatch]['diff_appsum_sle'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80a45356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:24:32.107058Z",
     "start_time": "2022-04-29T20:24:31.827964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sle_mismatch(min packets): 4.8% \n",
      "\n",
      "count    64646.000000\n",
      "mean        11.832735\n",
      "std         17.548010\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          4.000000\n",
      "75%         13.000000\n",
      "max        148.000000\n",
      "Name: diff_appsum_sle, dtype: float64"
     ]
    }
   ],
   "source": [
    "idx_mismatch_min_packets = (df_merge.sum_appsum_min_packets >= df_merge.diff_appsum_sle) & idx_sle_mismatch\n",
    "print(f\"sle_mismatch(min packets): {df_merge[idx_mismatch_min_packets]['count_appsum'].sum()*100/TOTAL_APPSUM_RECORDS:.1f}%\", \"\\n\")\n",
    "df_merge[idx_mismatch_min_packets]['diff_appsum_sle'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87706752-1ce8-4c93-8880-7c6ddc43c869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:24:43.993866Z",
     "start_time": "2022-04-29T20:24:43.952649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sle_mismatch(other): 0.002% \n",
      "\n",
      "count    8.00000\n",
      "mean     2.37500\n",
      "std      1.30247\n",
      "min      1.00000\n",
      "25%      1.75000\n",
      "50%      2.00000\n",
      "75%      3.00000\n",
      "max      5.00000\n",
      "Name: diff_appsum_sle, dtype: float64"
     ]
    }
   ],
   "source": [
    "idx_mismatch_other = (df_merge.sum_appsum_min_packets < df_merge.diff_appsum_sle) & idx_sle_mismatch\n",
    "print(f\"sle_mismatch(other): {df_merge[idx_mismatch_other]['count_appsum'].sum()*100/TOTAL_APPSUM_RECORDS:.3f}%\", \"\\n\")\n",
    "df_merge[idx_mismatch_other]['diff_appsum_sle'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62775c1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:18:22.520831Z",
     "start_time": "2022-04-29T20:18:22.491732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_merge['sle_mismatch'] = idx_sle_mismatch.values\n",
    "df_merge['sle_missing(min packets)'] = idx_missing_min_packets.values\n",
    "df_merge['sle_missing(other)'] = idx_missing_other.values\n",
    "df_merge['sle_mismatch(min packets)'] = idx_mismatch_min_packets.values\n",
    "df_merge['sle_mismatch(other)'] = idx_mismatch_other.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "979e8df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:18:23.490802Z",
     "start_time": "2022-04-29T20:18:23.430621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sle_mismatch(other): #appsum records = 619.0\n",
      "sle_mismatch(other): #sle records = 600.0\n",
      "sle_mismatch(other): #diff records = 19.0"
     ]
    }
   ],
   "source": [
    "print(f\"sle_mismatch(other): #appsum records = {df_merge[idx_mismatch_other]['count_appsum'].sum()}\")\n",
    "print(f\"sle_mismatch(other): #sle records = {df_merge[idx_mismatch_other]['count_sle'].sum()}\")\n",
    "print(f\"sle_mismatch(other): #diff records = {df_merge[idx_mismatch_other]['diff_appsum_sle'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61c260be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:18:23.046262Z",
     "start_time": "2022-04-29T20:18:23.015290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from io import StringIO # python3; python2: BytesIO \n",
    "# import boto3\n",
    "\n",
    "# bucket = 'mist-data-science-dev' # already created on S3\n",
    "# csv_buffer = StringIO()\n",
    "# df_temp = df_merge.to_csv(csv_buffer)\n",
    "# s3_resource = boto3.resource('s3')\n",
    "# temp_filepath = f\"ruchitm/app-health-{env}/diff/{'-'.join(group_cols)}/dt={date_string}/sle_mismatch.csv\"\n",
    "# s3_resource.Object(bucket, temp_filepath).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "452dec42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:18:23.685563Z",
     "start_time": "2022-04-29T20:18:23.654499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: diff_appsum_sle, dtype: float64"
     ]
    }
   ],
   "source": [
    "df_merge[df_merge.diff_appsum_sle < 0.]['diff_appsum_sle'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a2d2685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T20:18:23.886725Z",
     "start_time": "2022-04-29T20:18:23.857982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       0\n",
      "unique      0\n",
      "top       NaN\n",
      "freq      NaN\n",
      "Name: hour, dtype: object"
     ]
    }
   ],
   "source": [
    "df_merge[df_merge.diff_appsum_sle < 0.]['hour'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
